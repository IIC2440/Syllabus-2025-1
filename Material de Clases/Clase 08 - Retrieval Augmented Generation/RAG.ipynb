{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6b49fbd-a4d4-43d3-a3e2-051f52f4207e",
   "metadata": {},
   "source": [
    "# Actividad 3: Retreival-Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aebc40-3e9d-4c28-86ed-9869e4d09fc0",
   "metadata": {},
   "source": [
    "En esta actividad vas a descubrir cómo se implementa un sistema de RAG. \n",
    "La evaluación de esta actividad considera que puedas producir respuestas para un contexto en particular, tomando en cuenta distintas sensibilidades a la hora de entregar informaicón al LLM. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede910a8-66ad-4d4c-a588-4e46b0f09228",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Puedes usar el yaml proporcionado en el repositorio para instalar un ambiente que tenga todo lo necesario para estas importaciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ef78caa-d033-4967-8b05-476c01e56be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.embeddings import Embeddings\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "945a7f86-3d19-4ffb-a2e2-9cdaa8915887",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Poner la llave aquí! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e4f740-0ed9-43fb-aa60-6bf76c72aa3c",
   "metadata": {},
   "source": [
    "## El modelo que computa los vectores \n",
    "\n",
    "SentenceTransformer tiene los modelos necesarios para realizar el computo de string a vectores. \n",
    "Pero Langchain espera que le pasemos un modelo con métodos embed_documents() y embed_query(). \n",
    "Como vemos más abajo, en el modelo que usamos (E5) la diferencia entre la consulta y los documentos es que antemonemos el prefijo query: y passage: antes de computar el embedding de la consulta y de cada documento. Entonces, nuestros métodos realizaran justo eso. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b046af4-1fb3-4e53-8508-2f4600a586f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juan/downloads/ENTER/envs/st_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2.45292205e-02, -7.28081120e-03,  2.01645643e-02, -5.65277226e-02,\n",
       "        8.51372033e-02, -2.35328730e-02,  4.12015505e-02,  4.14172672e-02,\n",
       "        3.62707637e-02,  7.79401185e-03,  6.08525425e-02,  1.03171812e-02,\n",
       "        6.10303842e-02, -6.44690078e-03, -5.33033982e-02, -2.79593244e-02,\n",
       "        4.31734063e-02, -3.43652293e-02, -2.49172188e-03, -5.61207123e-02,\n",
       "        2.41614040e-02, -5.16346376e-03, -4.39666212e-02,  5.65978251e-02,\n",
       "        5.24599999e-02,  3.17301638e-02, -1.69265643e-02,  3.47117186e-02,\n",
       "        1.48336720e-02, -8.94378573e-02, -3.34181599e-02, -3.02848890e-02,\n",
       "        3.99507657e-02, -6.80900142e-02,  8.49799812e-02,  8.68255869e-02,\n",
       "       -4.44168448e-02, -4.32018116e-02,  7.44791254e-02, -1.73933040e-02,\n",
       "       -6.46682084e-02,  1.97995491e-02,  6.23653494e-02,  8.02007690e-02,\n",
       "        5.98563179e-02,  4.08843830e-02, -6.41530827e-02, -5.04073827e-03,\n",
       "       -2.49871630e-02, -3.49131376e-02, -5.10251820e-02,  6.24195635e-02,\n",
       "        2.44532749e-02,  5.82459643e-02,  6.02452345e-02, -1.12297401e-01,\n",
       "       -3.27717736e-02, -6.04390502e-02, -7.51304924e-02,  6.84655234e-02,\n",
       "        6.38708621e-02, -6.62072189e-03, -9.40370373e-03,  2.79463138e-02,\n",
       "        6.00733422e-02,  7.39925280e-02,  6.13325126e-02,  3.96705009e-02,\n",
       "       -1.28307408e-02, -8.05767160e-03, -5.09390011e-02,  5.78955337e-02,\n",
       "        1.72234653e-03, -2.26419922e-02,  4.34040911e-02, -8.49739835e-03,\n",
       "        3.13970968e-02, -7.74166435e-02,  9.76213589e-02, -7.31250867e-02,\n",
       "       -3.66376974e-02, -7.89370537e-02, -5.89655451e-02,  1.36568807e-02,\n",
       "       -6.86010197e-02,  7.08915815e-02,  9.91741288e-03, -5.64241596e-02,\n",
       "        6.06467910e-02, -4.69949171e-02,  3.74527015e-02,  4.92269769e-02,\n",
       "       -6.72360733e-02, -6.33844882e-02, -7.33730569e-02, -5.50508089e-02,\n",
       "       -6.37843087e-03,  4.50262763e-02,  4.55806293e-02, -4.94337194e-02,\n",
       "        3.09692882e-02, -2.68372763e-02,  6.87455684e-02, -8.81071910e-02,\n",
       "       -4.76621985e-02,  8.27858597e-02,  7.89474845e-02, -5.36921583e-02,\n",
       "        4.77639809e-02, -1.08677916e-01, -2.28356216e-02,  4.92353179e-02,\n",
       "        5.31412885e-02,  5.62636517e-02, -8.84907767e-02,  5.73675102e-03,\n",
       "       -1.66895594e-02, -4.89421003e-02,  5.84580712e-02, -9.54126120e-02,\n",
       "        4.37967367e-02, -7.77750537e-02, -5.00889234e-02, -2.98145674e-02,\n",
       "       -6.89356625e-02, -9.46722031e-02,  1.36551466e-02,  3.43018547e-02,\n",
       "        2.55801845e-02,  3.35620269e-02,  5.74161038e-02,  3.99255827e-02,\n",
       "        5.42160235e-02,  4.24634516e-02,  5.41999526e-02,  3.79771441e-02,\n",
       "       -3.50018195e-03,  3.39506492e-02, -3.05391531e-02,  7.75326553e-05,\n",
       "       -6.02763705e-02,  4.44728881e-02, -3.15176472e-02,  4.60332260e-03,\n",
       "        4.70601283e-02,  2.90595777e-02,  5.57980463e-02, -2.40808856e-02,\n",
       "        7.21674562e-02, -2.45056655e-02,  4.56920229e-02, -2.44390834e-02,\n",
       "        4.06590588e-02,  6.01114612e-03,  4.74545620e-02, -4.44451421e-02,\n",
       "       -4.96528633e-02, -3.89230624e-02,  3.32175121e-02,  6.54640049e-02,\n",
       "       -8.58396888e-02, -3.35885063e-02, -6.03794605e-02, -2.39446871e-02,\n",
       "       -1.66527480e-02, -3.54282185e-02, -5.96646871e-03,  1.10815868e-01,\n",
       "       -2.22986396e-02, -1.94621962e-02, -4.31088582e-02,  3.09812557e-02,\n",
       "       -7.76965320e-02,  1.30296161e-03, -5.15800416e-02,  5.86956628e-02,\n",
       "       -2.94879265e-02,  1.01310126e-01,  8.36715549e-02,  4.36473638e-02,\n",
       "       -5.43839224e-02,  8.14674608e-03, -8.43648762e-02, -2.82568615e-02,\n",
       "       -7.08193928e-02, -4.99428548e-02, -8.21685717e-02,  4.74624708e-02,\n",
       "        2.87477076e-02, -4.83025350e-02, -3.35669518e-02,  7.42692426e-02,\n",
       "       -2.01472081e-03, -8.96417052e-02, -4.76591997e-02,  3.90117578e-02,\n",
       "       -6.46739304e-02,  1.62689835e-02,  7.10558817e-02,  1.82105601e-02,\n",
       "       -2.04056930e-02, -3.39721926e-02,  2.95900311e-02,  3.17449868e-02,\n",
       "        7.59280920e-02, -3.19309090e-03, -4.90546040e-02,  4.21026349e-02,\n",
       "       -8.34062174e-02,  4.45693396e-02,  7.42447749e-02, -6.77918196e-02,\n",
       "       -1.06927074e-01,  3.12839821e-02, -6.55611455e-02, -5.39817587e-02,\n",
       "       -2.16687634e-03,  1.03500292e-01, -3.81000526e-02,  2.45788693e-02,\n",
       "        6.43568784e-02, -5.67477830e-02,  6.30650297e-02, -3.98234278e-02,\n",
       "       -5.89743033e-02,  3.57284881e-02,  8.18689540e-03, -5.01800142e-02,\n",
       "       -4.85119596e-02,  4.87746745e-02, -5.18575199e-02, -2.11659018e-02,\n",
       "       -9.59321633e-02, -6.02245219e-02, -3.26261073e-02, -5.20661734e-02,\n",
       "       -2.12309323e-02,  3.08510009e-03,  6.00305013e-02, -5.13718314e-02,\n",
       "       -2.43871799e-03, -4.03442420e-02,  8.15071315e-02, -4.38583009e-02,\n",
       "        6.46938682e-02, -2.54697576e-02, -2.08043475e-02,  6.27519190e-02,\n",
       "        1.86218359e-02,  5.20213209e-02,  3.47696780e-03, -8.69128704e-02,\n",
       "       -1.83309112e-02, -8.66857022e-02, -2.95801517e-02,  7.33254652e-04,\n",
       "        7.15654045e-02,  9.08946693e-02, -2.75858305e-02, -1.36341769e-02,\n",
       "        3.49810086e-02, -1.54920137e-02,  6.94034100e-02,  6.86292574e-02,\n",
       "        3.58099192e-02,  1.83140468e-02, -4.06811014e-02, -5.23538105e-02,\n",
       "       -8.92634839e-02, -4.92156595e-02, -2.20831241e-02, -9.55703016e-03,\n",
       "        1.05222382e-01, -4.19779234e-02, -3.93726937e-02, -2.12827884e-02,\n",
       "        4.78627607e-02,  8.86360481e-02, -2.05201302e-02, -5.07745007e-03,\n",
       "        5.00346981e-02,  2.56179925e-02,  4.76654917e-02,  5.31598516e-02,\n",
       "        6.02024309e-02,  5.62721025e-03, -5.09232841e-02,  6.64576516e-02,\n",
       "       -4.57390994e-02, -2.08651405e-02, -2.25684512e-02, -4.27157395e-02,\n",
       "        4.15178165e-02, -7.99556300e-02,  4.42864820e-02,  5.57222925e-02,\n",
       "        3.28314602e-02,  2.38648839e-02, -5.72160520e-02,  4.38033007e-02,\n",
       "       -4.11033519e-02, -5.86488210e-02,  3.58380079e-02, -1.44590866e-02,\n",
       "       -5.17079644e-02,  1.82745885e-02, -4.80523240e-03, -1.32801440e-02,\n",
       "        1.13461632e-02,  3.95708792e-02,  5.64413443e-02,  4.96497117e-02,\n",
       "       -1.85573716e-02, -3.72718796e-02,  3.64560485e-02,  6.08408079e-02,\n",
       "       -2.01451704e-02, -1.18621970e-02, -1.17513463e-02, -5.56072108e-02,\n",
       "       -4.32030596e-02, -8.23170170e-02, -3.07430904e-02, -1.87271703e-02,\n",
       "        5.78562878e-02, -1.38930501e-02, -5.02056368e-02, -2.55546942e-02,\n",
       "        5.99242970e-02,  1.98031534e-02,  3.83539461e-02, -9.11323130e-02,\n",
       "       -6.19281828e-02,  7.26819560e-02, -8.06041285e-02, -2.63446756e-02,\n",
       "       -1.55718187e-02,  5.09745032e-02, -3.38815264e-02, -4.03662324e-02,\n",
       "        1.44549757e-02,  3.40143368e-02, -4.14239354e-02,  6.80231899e-02,\n",
       "       -5.64552378e-03, -5.33624217e-02,  4.90996130e-02, -5.10121845e-02,\n",
       "       -3.17148119e-02,  7.90823922e-02,  4.00488079e-02, -1.09502196e-01,\n",
       "        3.69022638e-02,  7.68610165e-02, -2.57699527e-02,  2.96160346e-03,\n",
       "       -9.33482498e-02,  8.63733981e-03,  2.97474843e-02,  4.84039411e-02,\n",
       "       -4.86068204e-02, -3.24012414e-02,  3.62546146e-02, -4.26237332e-03,\n",
       "        8.54166150e-02,  4.93884347e-02,  1.45545816e-02, -5.31283431e-02,\n",
       "        5.51928915e-02, -3.33962068e-02,  4.35701273e-02,  3.53778526e-02,\n",
       "       -7.10435137e-02, -6.56634709e-03, -2.69238204e-02, -7.05235377e-02,\n",
       "       -6.09338842e-02,  5.87900989e-02, -4.85337973e-02, -3.62587050e-02,\n",
       "        5.21999858e-02,  2.72257868e-02,  6.01292998e-02,  2.31071152e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Primero un ejemplo de como funciona este sentence transformer. \n",
    "### Al crear esta clase, le pasamos a la librería SentenceTransformer \n",
    "### El modelo que queremos, y que hardware usar. \n",
    "\n",
    "model = SentenceTransformer(\"intfloat/multilingual-e5-small\",\"cpu\")\n",
    "model.encode(\"hola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "225ef38f-5ca4-4650-88a5-3ec691db66eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ahora preparamos la clase para langchain, con los métodos necesarios. \n",
    "\n",
    "class SentenceTransformerEmbeddings(Embeddings):\n",
    "    # Usamos intfloat/multilingual-e5-small, en la cpu.\n",
    "    def __init__(self, model_name=\"intfloat/multilingual-e5-small\", device=\"cpu\", prompt=\"passage: \"):\n",
    "        self.model = SentenceTransformer(model_name, device=device)\n",
    "        self.prompt = prompt\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        # Add prompt to each text (E5 model expects it!)\n",
    "        texts = [self.prompt + text for text in texts]\n",
    "        return self.model.encode(texts, normalize_embeddings=True).tolist()\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        # For queries, E5 expects \"query: ...\"\n",
    "        return self.model.encode([\"query: \" + text], normalize_embeddings=True)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82b9a2c4-5bcd-4c9c-b82c-eaa01b7b4176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juan/downloads/ENTER/envs/st_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### Y ahora creamos una instancia de esta clase. \n",
    "\n",
    "model_name = \"intfloat/multilingual-e5-small\"\n",
    "device = \"cpu\"  # quienes quieran usar la gpu de un Apple pueden poner \"mps\"\n",
    "\n",
    "model = SentenceTransformer(model_name, device=device)\n",
    "\n",
    "### vamos a usar esto más adelante\n",
    "prompts = {\"query\": \"query: \", \"passage\": \"passage: \"}\n",
    "default_prompt_name = \"passage\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee24215-4bec-4a7d-aae5-00bff68baa4e",
   "metadata": {},
   "source": [
    "## Division en Tokens\n",
    "\n",
    "Al momento de dividir en tokens, debemos usar el mismo modelo que para los embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2754c495-a285-493e-9b2f-6bda428db183",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juan/downloads/ENTER/envs/st_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"intfloat/multilingual-e5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer,\n",
    "    keep_separator=True,\n",
    "    add_start_index=True,\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc69e36f-0925-4755-ae57-1c711ad8d457",
   "metadata": {},
   "source": [
    "## Cargando un pequeño texto en Chroma. \n",
    "\n",
    "La base de datos computará automáticamente los vector embeddings al almacenar el texto, es una de las gracias de usar la librería langchain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "817f5aba-5c5c-4eab-b6a6-1662b55cd8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "### Primero dividimos el texto en párrafos\n",
    "\n",
    "text = open(\"text.txt\", encoding=\"utf-8\").read()\n",
    "paragraphs = text.split(\"\\n\\n\") \n",
    "\n",
    "### Ahora cargamos el texto\n",
    "documents = [Document(page_content=para) for para in paragraphs if para.strip()]\n",
    "\n",
    "### Y ahora a dividir cada párrafo en chunks aún más pequeños, para que los maneje E5. \n",
    "### Esto no se va a ver en el texto de ejemplo, pero es importante cuando los parrafos \n",
    "### son grandes\n",
    "split_chunks = splitter.split_documents(documents)\n",
    "\n",
    "print(len(documents))\n",
    "print(len(split_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39d47fba-9a69-42df-a62e-b2725fba9cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ahora creamos una instancia de Chroma. No es persistente, por lo que quedará en memoria\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=SentenceTransformerEmbeddings(\n",
    "        model_name=\"intfloat/multilingual-e5-small\",\n",
    "        device=\"cpu\"\n",
    "    ),\n",
    "    collection_name=\"my_collection\",\n",
    "    persist_directory=None   # acá podemos hacerlo persistente\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8700897e-c96d-4563-afb8-99b3edd7d263",
   "metadata": {},
   "source": [
    "## Agente RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "566d6851-0ddd-43f3-9d14-ab7b0db7cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Que LLM vamos a usar\n",
    "\n",
    "llm_generation = ChatOpenAI(model=\"gpt-4.1-mini\",\n",
    "                 temperature=0,\n",
    "                 openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "### Con que BD de vectores vamos a hacer el retrieval. \n",
    "### IMPORTANTE: search_kwargs es la cantidad de documentos que me entrega. \n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ebb1188-4206-42a5-ab0a-be55c84b5a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Algunas funciones que nos ayudan:\n",
    "\n",
    "### Esta funcion llama al retriever con una user query. \n",
    "def get_context_documents(user_query, retriever):\n",
    "    retrieved_docs = retriever.invoke(user_query)\n",
    "    return retrieved_docs\n",
    "\n",
    "### Formateo\n",
    "def format_context_documents(docs):\n",
    "    return \"\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a38d3007-7679-457b-a206-f0beab711348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Las ballenas jorobadas migran miles de kilómetros cada año entre zonas de alimentación y de reproducción.'\n"
     ]
    }
   ],
   "source": [
    "### Ejemplo de uso de RAG. Con una query, el retriever nos da los docs más parecidos. \n",
    "### ¿Ves que tiene sentido?\n",
    "user_query = \"¿Qué animales migran largas distancias todos los años?\"\n",
    "docs = get_context_documents(user_query, retriever)\n",
    "rag_context = format_context_documents(docs)\n",
    "\n",
    "print(docs[0])\n",
    "#print(rag_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0c1b21c-11d8-474b-9788-c56f9475ec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Y aquí está la magia. Con la user_query, vamos a buscar los docs al retriever y \n",
    "### generamos un mejor prompt\n",
    "\n",
    "def generate_agent_answer(user_query, retriever=retriever, llm_generation=llm_generation):\n",
    "    docs = get_context_documents(user_query, retriever)\n",
    "    rag_context = format_context_documents(docs)\n",
    "\n",
    "    answer_prompt = f\"\"\"Given the following user question and additional context, answer the user question in Spanish.\n",
    "    Question: {user_query}\n",
    "    Additional Context: {rag_context}\n",
    "    Answer: \"\"\"\n",
    "\n",
    "    # Respuesta LLM\n",
    "    return llm_generation.invoke(answer_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c22a148-8d6e-4e3b-80e8-5dfd3620b5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los animales que migran largas distancias todos los años son las ballenas jorobadas y las tortugas marinas. Las ballenas jorobadas migran miles de kilómetros entre sus zonas de alimentación y reproducción, mientras que las tortugas marinas recorren grandes distancias para regresar a las playas donde nacieron y poner sus huevos.\n"
     ]
    }
   ],
   "source": [
    "response = generate_agent_answer(\"¿Qué animales migran largas distancias todos los años?\", retriever=retriever, llm_generation=llm_generation)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eaad8f25-6577-42b9-9cfe-20037d3ddfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tengo información sobre varios animales y hábitats, incluyendo las ballenas jorobadas, las tortugas marinas, el lince ibérico y las abejas. También tengo información sobre hábitats como los arrecifes de coral y la selva tropical del Amazonas.\n"
     ]
    }
   ],
   "source": [
    "### Puedes ver por que esta consulta no es respondida tan bien?\n",
    "response = generate_agent_answer(\"De que animales o habitats tienes información\", retriever=retriever, llm_generation=llm_generation)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814c0bec-e399-4eed-bd06-654a3a06eca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (st_env_3)",
   "language": "python",
   "name": "st_env_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
